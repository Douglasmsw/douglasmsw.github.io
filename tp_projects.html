<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
		<link rel="stylesheet" href="assets/css/main.css">
	</head>
	
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<header id="header">
								<h4><a href="index.html" class="logo"><strong>Douglas Williams</strong></a></h4>
								<ul class="icons">
									<li>
										<a href="https://www.linkedin.com/in/douglasmsw/" class="image">
										<img src="images/icons8-linkedin.svg" alt="" /></a>
									</li>
									<li>
										<a href="https://github.com/Douglasmsw" class="image">
										<img src="images/icons8-github.svg" alt="" /></a>
									</li>
								</ul>
							</header>

							<!-- Content -->
								<section>
									<header class="main">
										<h1>Tech Policy Projects</h1>
									</header>

									<h2>Expertise Assymetry and Government Tech Procurement: Lessons from the LAPD</h2>
									<p>Recent scholarly work on predictive policing has identified a need to study the techno-social factors that influence program success. This case study draws on police interviews, recent sociological theory, and both journalistic and governmental reports to characterize how the Los Angeles Police Department’s (LAPD’s) history of corruption and post-9/11 federal policing initiatives drove LAPD management to contract the services of the predictive policing company PredPol. While contracted with PredPol, no thorough analysis was conducted to see if the LAPD’s deployment of PredPol’s tools reduced crime in the field or increased police management-officer tensions. I address these shortcomings and document how police officers mounted a data obfuscation campaign that reduced departmental transparency. Despite this, the LAPD worked with PredPol for 8 years. To protect against wasteful or even harmful technology-based government contracting, I propose incorporating causal experimentation trials, government-client goal-setting, and regular bias and outcome audit requirements into city government procurement guidelines. By shifting auditing responsibility to technology providers, these recommendations account for the lack of technical expertise often present in city government staff while creating beneficial competition in the acquisition phase of government contracting. These recommendations also create a paper trail allowing external stakeholders to engage in contracting decisions and hold both governmental and company actors accountable. Overall, this case study highlights how technical expertise asymmetry in these contracting relationships allows reputation, not results, to dictate the implementation of programs; and underscores the need for procurement standards in the policing tech, and government tech, industry at large.</p>
									<p>The paper (asbtract above) I wrote in undergrad can be read at <a href="https://docs.google.com/document/d/12HPEf8oHYPNi6HAb0D7WVmSnDsr5zSuhtd3eFL_F9bQ/edit?usp=sharing" target="_blank" rel="noopener noreferrer">this link</a>. I originally wrote this for my Policy Implementation class and won the Harper Award for Academic Excellence.</p>
									
									<hr class="major" />

									<h2>AI Hiring Tools, A Sociological and Legal Perspective</h2>
									<p>Inspired by a Harvard Business Review paper which found a large population of people who find it nearly impossible to get job interviews, I wanted to explore the regulatory regime surrounding and potential harms of the growing automated hiring tech industry. This industry provides a suite of tools to automate parts of the hiring process. But as these tools are purchased and applied across industries, the potential for biased, innacurate, or just poorly designed computational methods to harm thousands if not millions of job applicants scales scarily fast.</p>
									<p>For this project, which can be read <a href="https://docs.google.com/document/d/1x2Vh3CVJ8bErd-u_0T2RzvZIyzyRLkH9VOpQRGfk6O4/edit?usp=sharing" target="_blank" rel="noopener noreferrer">here</a>, I looked into the historical impetus for these tools and their current sociological motivations for adoption. I then delve into the world of anti-discrimination law to see how the law covers the potential harms of this rapidly growing industry. I end with a policy reccomendation to help hold companies responsible for the models they produce and a possible argumentation framework for legal teams to employ in court.</p>
									
									<hr class="major" />

									<h2>AI Hiring Tools, A Technical Perspective</h2>
									<p>The above project looks to explore the sociological and legal dimensions of automated hiring tools. But a key question remains: do hiring tools introduce systemic discrimination? If so, against what groups? How can we detect / meaure it? To address this question I put on my computer scientist cap (and blew some money I'd won for another project of mine) to do a proof of concept study comparing how humans and natural language processing (NLP) methods assess and rank resumes. In short, I payed people who had professional hiring experience to read resumes for a job posting and (1) list what skills they believe the applicant had that were relevant to the job posting and (2) rank the top 4 applicants best qualified for the job. I then used ChatGPT to do task (1) and devised a set of crude NLP methods to do task (2). Lastly, I compared the humans to the computers to see how they differentially interpreted resumes and if any interesting bias or patterns appeared.</p>
									<p>The final write-up can be found <a href="https://docs.google.com/document/d/1TeVJfCTEVeHeECj5y56B3TqFyPhI9nyQ139QifXbAgE/edit?usp=sharing" target="_blank" rel="noopener noreferrer">at this link</a>. Some interesting findings were that (1) humans weighted soft skills more heavily in their evaluations, (2) it is possible to compare and measure concepts like bias and selection processes for human and computational methods at scale, and (3) with subtle changes to the NLP selection method's parameters we could change selection patterns to match desired properties. This was meant as a test to see if this comparative methodology could work, and I feel enthusiastic about what a scaled up and more sophisticated version could find!.</p>

									<hr class="major" />
									
								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="index.html">Homepage</a></li>
										<li>
											<span class="opener">Projects</span>
											</a>
											<ul>
												<li><a href="hl_projects.html">Homelessness</a></li>
												<li><a href="cv_projects.html">Computer & Data Science</a></li>
												<li><a href="tp_projects.html">Tech Policy</a></li>
												<li><a href="ps_projects.html">Philosophy of Science</a></li>
											</ul>
										</li>
									</ul>
								</nav>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<p>I'm always trying to meet like-minded people in local government, organizing, and academia. Please reach out!</p>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="#">douglasmsw@gmail.com</a></li>
									</ul>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; Douglas Williams. All rights reserved. Design: <a href="https://html5up.net" target="_blank" rel="noopener noreferrer">HTML5 UP</a>.</p>
								</footer>

						</div>
						<a href="#sidebar" class="toggle">Toggle</a>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
